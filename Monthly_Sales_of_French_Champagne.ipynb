{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Monthly Sales of French Champagne.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QqURviJdHRZ"
      },
      "source": [
        "# **Project: Monthly Sales of French Champagne**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbn560Ma9NUy"
      },
      "source": [
        "**Statement**:\n",
        "\n",
        "  In this problem we will try to prdict the number of monthly sales of champagne for the well-known French champagne company ***Perrin Frères***.\n",
        "  The dataset is credited to **Makridakis** & **Wheelwrigt**, 1989. It describes the number of month sales of champagne from January 1964-September 1972.\n",
        "\n",
        "The steps of this project that we will through are as follows.\n",
        "\n",
        "* The steps:\n",
        "      1. Problem Description.\n",
        "      2. Test Harness.\n",
        "      3. Persistence.\n",
        "      4. Data Analysis.\n",
        "      5. ARIMA Models.\n",
        "      6. Model Validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kpFlsgTg2dt"
      },
      "source": [
        "!pip install -U mxnet-cu101==1.7.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 1,
        "tab": [
          "mxnet"
        ],
        "id": "x1aS_K_pgvYw"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFMx4b7ohdFJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 7,
        "tab": [
          "mxnet"
        ],
        "id": "xhp98FxhgvY0"
      },
      "source": [
        "from mxnet import np, npx\n",
        "from mxnet.gluon import nn\n",
        "\n",
        "npx.set_np()\n",
        "\n",
        "npx.cpu(), npx.gpu(), npx.gpu(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz206L6yhlQe"
      },
      "source": [
        "npx.num_gpus() #Query the number of available gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDRlz7Kwk555"
      },
      "source": [
        "# Test Harness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_By8jXOO9OjI"
      },
      "source": [
        "from pandas import read_csv\n",
        "\n",
        "series  = read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly_champagne_sales.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
        "split_point = len(series) - 12\n",
        "dataset, validation = series[0:split_point], series[split_point:]\n",
        "print('Dataset %d, Validation %d' % (len(dataset), len(validation)))\n",
        "dataset.to_csv('dataset.csv', header=False)\n",
        "validation.to_csv('validation.csv', header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izc1X_wvjiau"
      },
      "source": [
        "**The specific contents of these files are:**\n",
        "\n",
        "    1. dataset.csv: Observations from January 1964 to September 1971 (93 obs)\n",
        "    2. validation.csv: Observations from October 1971 to September 1972 (12 obs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpqWgQwsknrU"
      },
      "source": [
        "## **Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtByZMC4dgVY"
      },
      "source": [
        "# evaluate persistence model on time series\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "# load data\n",
        "series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "# prepare data\n",
        "X = series.values\n",
        "X = X.astype('float32')\n",
        "train_size = int(len(X) * 0.50)\n",
        "train, test = X[0:train_size], X[train_size:]\n",
        "# walk-forward validation\n",
        "history = [x for x in train]\n",
        "predictions = list()\n",
        "for i in range(len(test)):\n",
        "  # predict\n",
        "  yhat = history[-1]\n",
        "  predictions.append(yhat)\n",
        "  # observation\n",
        "  obs = test[i]\n",
        "  history.append(obs)\n",
        "  print( ' >Predicted=%.3f, Expected=%3.f ' % (yhat, obs))\n",
        "# report performance\n",
        "rmse = sqrt(mean_squared_error(test, predictions))\n",
        "print( ' RMSE: %.3f ' % rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cweGwIjmme5"
      },
      "source": [
        "*We can see that the persistence model achieved an **RMSE of 3186.501**. This means that on average, the model was wrong by about 3,186 million sales for each prediction made.*\n",
        "We now a baseline prediction method and performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcKnNEflnOob"
      },
      "source": [
        "## **Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWuGGraGl4q3"
      },
      "source": [
        "series.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhPHbhAHngm6"
      },
      "source": [
        "# Line Plot\n",
        "from matplotlib import pyplot\n",
        "series.plot()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KsIYuC-odg2"
      },
      "source": [
        "The plot shows an increase trend of sales over time and appears to be systematic seasonality to the sales for each year. Therefore the seasonal signal appears to be growing over time. However we do not notice any outliers and its certainly a non-stationary series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odEvzcskoLk0"
      },
      "source": [
        "# Seasonal Line Plots - Multiple line plots of time series\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import Grouper\n",
        "from matplotlib import pyplot\n",
        "series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "groups = series['1964' : '1970'].groupby(Grouper(freq='A'))\n",
        "years = DataFrame()\n",
        "pyplot.figure()\n",
        "i = 1\n",
        "n_groups = len(groups)\n",
        "for name, group in groups:\n",
        "  pyplot.subplot((n_groups*100) + 10 + i)\n",
        "  i += 1\n",
        "  pyplot.plot(group)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJr2C02qsN45"
      },
      "source": [
        "# density plots of time series\n",
        "from pandas import read_csv\n",
        "from matplotlib import pyplot\n",
        "series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "pyplot.figure(1)\n",
        "pyplot.subplot(211)\n",
        "series.hist()\n",
        "pyplot.subplot(212)\n",
        "series.plot(kind='kde')\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhx1_SVFsq4J"
      },
      "source": [
        "# boxplots of time series\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import Grouper\n",
        "from matplotlib import pyplot\n",
        "series = read_csv('dataset.csv' , header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "groups = series['1964' : '1970'].groupby(Grouper(freq= 'A' ))\n",
        "years = DataFrame()\n",
        "for name, group in groups:\n",
        "  years[name.year] = group.values\n",
        "years.boxplot()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pFc3sV1tS9j"
      },
      "source": [
        "# ARIMA Models\n",
        "\n",
        "1. Manually Configure the ARIMA.\n",
        "2. Automatically Configure the ARIMA.\n",
        "3. Review Residual Errors.32.6. ARIMA Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIGQtlEBs6qI"
      },
      "source": [
        "# create and summarize stationary version of time series - Manual Configuration\n",
        "from pandas import read_csv\n",
        "from pandas import Series\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# create a differenced series\n",
        "def difference(dataset, interval=1):\n",
        "  diff = list()\n",
        "  for i in range(interval, len(dataset)):\n",
        "    value = dataset[i] - dataset[i - interval]\n",
        "    diff.append(value)\n",
        "  return Series(diff)\n",
        "series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "X = series.values\n",
        "X = X.astype('float32')\n",
        "# difference data\n",
        "months_in_year = 12\n",
        "stationary = difference(X, months_in_year)\n",
        "stationary.index = series.index[months_in_year:]\n",
        "# check if stationary\n",
        "result = adfuller(stationary)\n",
        "print( 'ADF Statistic: %f' % result[0])\n",
        "print( 'p-value: %f' % result[1])\n",
        "print( 'Critical Values:' )\n",
        "for key, value in result[4].items():\n",
        "  print( '\\t%s: %.3f' % (key, value))\n",
        "# save the deseasonalized version of the series\n",
        "stationary.to_csv('stationary.csv', header=False)\n",
        "# plot\n",
        "stationary.plot()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LoZL3gfvWOo"
      },
      "source": [
        "The results show that the test statistic value -7.134898 is smaller than the critical value at 1% of -3.515. This suggests that we can reject the null hypothesis H0 with a significance level of less than 1%. Meaning a\n",
        "low probability that the result is a statistical fluke. Rejecting the null hypothesis means that the process has no unit root, and in turn that the time series is stationary or does not have time-dependent structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB2WRS2Tv28R"
      },
      "source": [
        "# ACF and PACF plots of time series\n",
        "from pandas import read_csv\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "from matplotlib import pyplot\n",
        "\n",
        "series = read_csv('stationary.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "pyplot.figure()\n",
        "pyplot.subplot(211)\n",
        "plot_acf(series, lags=25, ax=pyplot.gca())\n",
        "pyplot.subplot(212)\n",
        "\n",
        "plot_pacf(series, lags=25, ax=pyplot.gca())\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aoDKmYpwh6C"
      },
      "source": [
        "# evaluate manually configured ARIMA model\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from math import sqrt\n",
        "\n",
        "# create a differenced series\n",
        "def difference(dataset, interval=1):\n",
        "  diff = list()\n",
        "  for i in range(interval, len(dataset)):\n",
        "    value = dataset[i] - dataset[i - interval]\n",
        "    diff.append(value)\n",
        "  return diff\n",
        "\n",
        "# invert differenced value\n",
        "def inverse_difference(history, yhat, interval=1):\n",
        "  return yhat + history[-interval]\n",
        "\n",
        "# load data\n",
        "series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "# prepare data\n",
        "X = series.values\n",
        "X = X.astype('float32')\n",
        "train_size = int(len(X) * 0.50)\n",
        "train, test = X[0:train_size], X[train_size:]\n",
        "# walk-forward validation\n",
        "history = [x for x in train]\n",
        "predictions = list()\n",
        "for i in range(len(test)):\n",
        "  # difference data\n",
        "  months_in_year = 12\n",
        "  diff = difference(history, months_in_year)\n",
        "  # predict\n",
        "  model = ARIMA(diff, order=(1,1,1)) # The model can be extended to ARIMA(1,1,1)\n",
        "  model_fit = model.fit(trend= 'nc', disp=0) # The trend arguments to nc\n",
        "  yhat = model_fit.forecast()[0]\n",
        "  yhat = inverse_difference(history, yhat, months_in_year)\n",
        "  predictions.append(yhat)\n",
        "  # observation\n",
        "  obs = test[i]\n",
        "  history.append(obs)\n",
        "  print( '>Predicted=%.3f, Expected=%.3f' % (yhat, obs))\n",
        "# report performance\n",
        "rmse = sqrt(mean_squared_error(test, predictions))\n",
        "print( 'RMSE: %.3f' % rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B1whrYxyQOt"
      },
      "source": [
        "Note: This result in an **RMSE of 956.960** show a better improvement than the persistence RMSE of 3186.501"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c3OJ7uhyqpt"
      },
      "source": [
        "## Grid Search ARIMA Hyperparameters\n",
        "\n",
        "We will search all\n",
        "combinations of the following parameters:\n",
        " * p: 0 to 6\n",
        " * d: 0 to 2\n",
        " * q: 0 to 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBmgdVsfyAKA"
      },
      "source": [
        "# grid search ARIMA parameters for time series\n",
        "import warnings\n",
        "from pandas import read_csv\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "import numpy\n",
        "\n",
        "# create a differenced series\n",
        "def difference(dataset, interval=1):\n",
        "  diff = list()\n",
        "  for i in range(interval, len(dataset)):\n",
        "    value = dataset[i] - dataset[i - interval]\n",
        "    diff.append(value)\n",
        "  return numpy.array(diff)\n",
        "\n",
        "# invert differenced value\n",
        "def inverse_difference(history, yhat, interval=1):\n",
        "  return yhat + history[-interval]\n",
        "\n",
        "# evaluate an ARIMA model for a given order (p,d,q) and return RMSE\n",
        "def evaluate_arima_model(X, arima_order):\n",
        "  # prepare training dataset\n",
        "  X = X.astype('float32')\n",
        "  train_size = int(len(X) * 0.50)\n",
        "  train, test = X[0:train_size], X[train_size:]\n",
        "  history = [x for x in train]\n",
        "  # make predictions\n",
        "  predictions = list()\n",
        "  for t in range(len(test)):\n",
        "    # difference data\n",
        "    months_in_year = 12\n",
        "    diff = difference(history, months_in_year)\n",
        "    model = ARIMA(diff, order=arima_order)\n",
        "    model_fit = model.fit(trend= 'nc', disp=0)\n",
        "    yhat = model_fit.forecast()[0]\n",
        "    yhat = inverse_difference(history, yhat, months_in_year)\n",
        "    predictions.append(yhat)\n",
        "    history.append(test[t])\n",
        "  # calculate out of sample error\n",
        "  rmse = sqrt(mean_squared_error(test, predictions))\n",
        "  return rmse\n",
        "\n",
        "# evaluate combinations of p, d and q values for an ARIMA model\n",
        "def evaluate_models(dataset, p_values, d_values, q_values):\n",
        "  dataset = dataset.astype('float32')\n",
        "  best_score, best_cfg = float(\"inf\"), None\n",
        "  for p in p_values:\n",
        "    for d in d_values:\n",
        "      for q in q_values:\n",
        "        order = (p,d,q)\n",
        "        try:\n",
        "          rmse = evaluate_arima_model(dataset, order)\n",
        "          if rmse < best_score:\n",
        "            best_score, best_cfg = rmse, order\n",
        "          print('ARIMA%s RMSE=%.3f' % (order,rmse))\n",
        "        except:\n",
        "          continue\n",
        "  print( 'Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))\n",
        "# load dataset\n",
        "series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "# evaluate parameters\n",
        "p_values = range(0, 7)\n",
        "d_values = range(0, 3)\n",
        "q_values = range(0, 7)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "evaluate_models(series.values, p_values, d_values, q_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYEAmSBI2je7"
      },
      "source": [
        "**We will select this ARIMA(4, 0, 1) model going forward.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OMfUyCk26q2"
      },
      "source": [
        "## Review Residual Errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KakeA-kW02Y4"
      },
      "source": [
        "# summarize ARIMA forecast residuals\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# create a differenced series\n",
        "def difference(dataset, interval=1):\n",
        "  diff = list()\n",
        "  for i in range(interval, len(dataset)):\n",
        "    value = dataset[i] - dataset[i - interval]\n",
        "    diff.append(value)\n",
        "  return diff\n",
        "\n",
        "# invert differenced value\n",
        "def inverse_difference(history, yhat, interval=1):\n",
        "  return yhat + history[-interval]\n",
        "\n",
        "# load data\n",
        "series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "# prepare data\n",
        "X = series.values\n",
        "X = X.astype('float32')\n",
        "train_size = int(len(X) * 0.50)\n",
        "train, test = X[0:train_size], X[train_size:]\n",
        "# walk-forward validation\n",
        "history = [x for x in train]\n",
        "predictions = list()\n",
        "for i in range(len(test)):\n",
        "  # difference data\n",
        "  months_in_year = 12\n",
        "  diff = difference(history, months_in_year)\n",
        "  # predict\n",
        "  model = ARIMA(diff, order=(4,0,1))\n",
        "  model_fit = model.fit(trend= 'nc', disp=0)\n",
        "  yhat = model_fit.forecast()[0]\n",
        "  yhat = inverse_difference(history, yhat, months_in_year)\n",
        "  predictions.append(yhat)\n",
        "  # observation\n",
        "  obs = test[i]\n",
        "  history.append(obs)\n",
        "# errors\n",
        "residuals = [test[i]-predictions[i] for i in range(len(test))]\n",
        "residuals = DataFrame(residuals)\n",
        "print(residuals.describe())\n",
        "# plot\n",
        "pyplot.figure()\n",
        "pyplot.subplot(211)\n",
        "residuals.hist(ax=pyplot.gca())\n",
        "pyplot.subplot(212)\n",
        "residuals.plot(kind= 'kde', ax=pyplot.gca())\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTWOcZGMD2eu"
      },
      "source": [
        "The distribution of residual errors is also plotted. The graphs suggest a Gaussian-like distribution with a bumpy left tail, providing further evidence that perhaps a power transform might be worth exploring."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJnQWa1J34GD"
      },
      "source": [
        "# Plots of residual errors of bias corrected forecasts\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# create a differenced series\n",
        "def difference(dataset, interval=1):\n",
        "  diff = list()\n",
        "  for i in range(interval, len(dataset)):\n",
        "    value = dataset[i] - dataset[i - interval]\n",
        "    diff.append(value)\n",
        "  return diff\n",
        "\n",
        "# invert differenced value\n",
        "def inverse_difference(history, yhat, interval=1):\n",
        "  return yhat + history[-interval]\n",
        "\n",
        "# load data\n",
        "series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "\n",
        "# prepare data\n",
        "X = series.values\n",
        "X = X.astype('float32')\n",
        "train_size = int(len(X) * 0.50)\n",
        "train, test = X[0:train_size], X[train_size:]\n",
        "\n",
        "# walk-forward validation\n",
        "history = [x for x in train]\n",
        "predictions = list()\n",
        "bias = 146.401198\n",
        "for i in range(len(test)):\n",
        "  # difference data\n",
        "  months_in_year = 12\n",
        "  diff = difference(history, months_in_year)\n",
        "  # predict\n",
        "  model = ARIMA(diff, order=(4,0,1))\n",
        "  model_fit = model.fit(trend='nc', disp=0)\n",
        "  yhat = model_fit.forecast()[0]\n",
        "  yhat = bias + inverse_difference(history, yhat, months_in_year)\n",
        "  predictions.append(yhat)\n",
        "  # observation\n",
        "  obs = test[i]\n",
        "  history.append(obs)\n",
        "# report performance\n",
        "rmse = sqrt(mean_squared_error(test, predictions))\n",
        "print('RMSE: %.3f' % rmse)\n",
        "# errors\n",
        "residuals = [test[i]-predictions[i] for i in range(len(test))]\n",
        "residuals = DataFrame(residuals)\n",
        "print(residuals.describe())\n",
        "# plot\n",
        "pyplot.figure()\n",
        "pyplot.subplot(211)\n",
        "residuals.hist(ax=pyplot.gca())\n",
        "pyplot.subplot(212)\n",
        "residuals.plot(kind= 'kde', ax=pyplot.gca())\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X64AVCZE6W4"
      },
      "source": [
        "The performance of the predictions is improved very slightly from 911.526 to 899.693, which may or may not be significant. The summary of the forecast residual errors shows that the mean was indeed moved to a value very close to zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R99A0OY5VE_"
      },
      "source": [
        "# ACF and PACF plots of residual errors of bias corrected forecasts\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from matplotlib import pyplot\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "\n",
        "# create a differenced series\n",
        "def difference(dataset, interval=1):\n",
        "  diff = list()\n",
        "  for i in range(interval, len(dataset)):\n",
        "    value = dataset[i] - dataset[i - interval]\n",
        "    diff.append(value)\n",
        "  return diff\n",
        "\n",
        "# invert differenced value\n",
        "def inverse_difference(history, yhat, interval=1):\n",
        "  return yhat + history[-interval]\n",
        "\n",
        "# load data\n",
        "series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "\n",
        "# prepare data\n",
        "X = series.values\n",
        "X = X.astype('float32')\n",
        "train_size = int(len(X) * 0.50)\n",
        "train, test = X[0:train_size], X[train_size:]\n",
        "# walk-forward validation\n",
        "history = [x for x in train]\n",
        "predictions = list()\n",
        "for i in range(len(test)):\n",
        "  # difference data\n",
        "  months_in_year = 12\n",
        "  diff = difference(history, months_in_year)\n",
        "  # predict\n",
        "  model = ARIMA(diff, order=(4,0,1))\n",
        "  model_fit = model.fit(trend= 'nc' , disp=0)\n",
        "  yhat = model_fit.forecast()[0]\n",
        "  yhat = inverse_difference(history, yhat, months_in_year)\n",
        "  predictions.append(yhat)\n",
        "  # observation\n",
        "  obs = test[i]\n",
        "  history.append(obs)\n",
        "# errors\n",
        "residuals = [test[i]-predictions[i] for i in range(len(test))]\n",
        "residuals = DataFrame(residuals)\n",
        "print(residuals.describe())\n",
        "# plot\n",
        "pyplot.figure()\n",
        "pyplot.subplot(211)\n",
        "plot_acf(residuals, ax=pyplot.gca())\n",
        "pyplot.subplot(212)\n",
        "plot_pacf(residuals, ax=pyplot.gca())\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVmd3DsiLyEU"
      },
      "source": [
        "* ACF and PACF plots of residual errors on the bias corrected ARIMA model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7xz-hqgGUmK"
      },
      "source": [
        "# Model Validation\n",
        "\n",
        "  * Finalize Model: Train and save the final model.\n",
        "  * Make Prediction: Load the finalized model and make a prediction.\n",
        "  * Validate Model: Load and validate the final model.\n",
        "\n",
        "  ## Finalize Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nLDNTbYF8nz"
      },
      "source": [
        "# save finalized model\n",
        "from pandas import read_csv\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "import numpy\n",
        "\n",
        "# monkey patch around bug in ARIMA class\n",
        "def __getnewargs__(self):\n",
        "  return ((self.endog),(self.k_lags, self.k_diff, self.k_ma))\n",
        "ARIMA.__getnewargs__ = __getnewargs__\n",
        "\n",
        "# create a differenced series\n",
        "def difference(dataset, interval=1):\n",
        "  diff = list()\n",
        "  for i in range(interval, len(dataset)):\n",
        "    value = dataset[i] - dataset[i - interval]\n",
        "    diff.append(value)\n",
        "  return diff\n",
        "\n",
        "# load data\n",
        "series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "\n",
        "# prepare data\n",
        "X = series.values\n",
        "X = X.astype('float32')\n",
        "# difference data\n",
        "months_in_year = 12\n",
        "diff = difference(X, months_in_year)\n",
        "# fit model\n",
        "model = ARIMA(diff, order=(4,0,1))\n",
        "model_fit = model.fit(trend= 'nc', disp=0)\n",
        "# bias constant, could be calculated from in-sample mean residual\n",
        "bias = 146.401198\n",
        "# save model\n",
        "model_fit.save( 'model.pkl' )\n",
        "numpy.save('model_bias.npy' , [bias])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hULDS3CIchz"
      },
      "source": [
        "   ### Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjDm3LWrJeMA"
      },
      "source": [
        "# load finalized model and make a prediction\n",
        "from pandas import read_csv\n",
        "from statsmodels.tsa.arima_model import ARIMAResults\n",
        "import numpy\n",
        "\n",
        "# invert differenced value\n",
        "def inverse_difference(history, yhat, interval=1):\n",
        "  return yhat + history[-interval]\n",
        "series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "months_in_year = 12\n",
        "model_fit = ARIMAResults.load('model.pkl')\n",
        "bias = numpy.load('model_bias.npy')\n",
        "yhat = float(model_fit.forecast()[0])\n",
        "yhat = bias + inverse_difference(series.values, yhat, months_in_year)\n",
        "print('Predicted: %.3f' % yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg_9gl73M2-s"
      },
      "source": [
        "## Model Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfQvwIgHJrjv"
      },
      "source": [
        "# load and evaluate the finalized model on the validation dataset\n",
        "from pandas import read_csv\n",
        "from matplotlib import pyplot\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from statsmodels.tsa.arima_model import ARIMAResults\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "import numpy\n",
        "\n",
        "# load and prepare datasets\n",
        "dataset = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "X = dataset.values.astype('float32')\n",
        "history = [x for x in X]\n",
        "months_in_year = 12\n",
        "validation = read_csv('validation.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "y = validation.values.astype('float32')\n",
        "\n",
        "# load model\n",
        "model_fit = ARIMAResults.load('model.pkl')\n",
        "bias = numpy.load('model_bias.npy')\n",
        "\n",
        "# make first prediction\n",
        "predictions = list()\n",
        "yhat = float(model_fit.forecast()[0])\n",
        "yhat = bias + inverse_difference(history, yhat, months_in_year)\n",
        "predictions.append(yhat)\n",
        "history.append(y[0])\n",
        "print('>Predicted=%.3f, Expected=%.3f' % (yhat, y[0]))\n",
        "\n",
        "# rolling forecasts\n",
        "for i in range(1, len(y)):\n",
        "  # difference data\n",
        "  months_in_year = 12\n",
        "  diff = difference(history, months_in_year)\n",
        "  # predict\n",
        "  model = ARIMA(diff, order=(4,0,1))\n",
        "  model_fit = model.fit(trend= 'nc', disp=0)\n",
        "  yhat = model_fit.forecast()[0]\n",
        "  yhat = bias + inverse_difference(history, yhat, months_in_year)\n",
        "  predictions.append(yhat)\n",
        "  # observation\n",
        "  obs = y[i]\n",
        "  history.append(obs)\n",
        "  print( '>Predicted=%.3f, Expected=%.3f' % (yhat, obs))\n",
        "# report performance\n",
        "rmse = sqrt(mean_squared_error(y, predictions))\n",
        "print('RMSE: %.3f' % rmse)\n",
        "pyplot.plot(y)\n",
        "pyplot.plot(predictions, color= 'red')\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vwmNe57TlKA"
      },
      "source": [
        "* Loading and validating the finalized model over the 12 months of forecast sales graph looks satistying.\n",
        "* Therefore the plot of the expected values is represented in Blue and the predictions in Red for the validation dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FWpz-4OYF0l"
      },
      "source": [
        "![images.jpeg](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAkGBw8QEA8QEBAWEA8PDw8QDxUWFRUVEhUPFRUWFhUVFRUaHSggGBolHRUVITEhJSkrLy8uFx8zODMsNygtLisBCgoKDg0OGxAQGy0iICUuLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0uLS0tLS0tLS0tLS0tLS0tLS0tLf/AABEIAOAA4QMBEQACEQEDEQH/xAAbAAEAAgMBAQAAAAAAAAAAAAAAAQUCAwQGB//EAEIQAAEDAgMEBwMLAgQHAAAAAAEAAgMEEQUhMRJBUXEGEyIyYYGRFEKhFTNSYmNygpKxwdEHI3Sy4fAWJENTg5Oi/8QAGgEBAAIDAQAAAAAAAAAAAAAAAAEDAgQFBv/EADERAQACAQIEBAQGAwEBAQAAAAABAgMEERIhMUEFE1FxMmGBkRQiQqGx0SNSwfAzFf/aAAwDAQACEQMRAD8A+2ICAgICCEBAQEEoCCEBAQEBBCAgICAgIIQEBBCAghAQbUBAQEBAQQglAQEEICAgICCEBAQEBAQEEICAghAQQgINqAgICAgIIQSgIIQQgICAglBCAgICAgIIQEBAQQghAQEG1AQEBAQQglBCAgIIQEBACAgICAgICAgIIQEEICCEBAQbEBBKCEBAQEBAQQgICAgIJQQgICAgICCEBBCAgIIQEC6DYgICAgICAgIIQEBAQEBAKAgICAghAQEBBCAgIIKAghBtQEBAQQgICAgICAgICAglBCAgICAghAQQgICAghAQQg2oCCEBAQEBAQHEDMmw8clja9a9Z2TEb9FBX9NcMhcWPq2OkGrIw6Z/5YwbLHzabb7nDKpxD+plHFsWp6uQyG0dodjaPACRwJ1G7esYzVt8M7pmsx1Jem1XYFmFTgHTadET5tDwQsbWz/piPqmIr3lxTdPp2/O08tOOLqd7mjm5pcFqZJ13bh/97s4jEmj6etlIDKqJ5O4bLXehz+C0MufXV6zMfRdFMS3i6QPOshHNrbfotOddrKz8f8LPKxz2dUeOPy7TXeX8FZV8Y1Veu0/RH4ejobjZ0LB5EhX08dv+qkfdhOljtLloOlsMtRUU/VuaacQkuBa5rhI0nLS1rWXQnxWlcVclqztbf9lXkTNpiJ6LduJQnV4bbM7WQA8Scldi8T02SdottPzY2w3js3wTMkaHsc17Do5pDmnkRkt/ffoqZoCCCgICAghAQQg2ICAgIACDTU1kUXzkjW+BOfpqqcmoxY/jtEMopaekKiq6TxjKJheeJ7Lf5K5+XxakcqRv+0Lq6ee6ul6SzOG5v3cvic1zM3iGoydLcMfKP+rq4aQpcTl9oa5sxLmuFiNpwy5g3WrW9q24t95+fNZtHRVyyx0zY4aaFvWynZhjYA0EjVzyNGAZk/ytvBiyau/5p5K7WikLXCcKEJ62R3XVTh25To0fQib7jfid69Hiw1xV4aw07Wm3OV3S0j5DrZvHd5cVaxWkGGxNzPaPjp6KBpxHBKCoympYZfvRMcRyJFwoFTL0Ew+x6nrqU/YzSNb+Rxc34Ku+HHf4oiWUXmFcehdY0gw4ltAbp6drifxxuZ+i1b+HYLdtmcZrQpMZ+VKSWGKRlPIKl3VRStdI2LrLXDXg5tJ3DO+5ambw3DjrN5mdoW1zWtOzqgdDhrXvnk66sq3Bzmxt7chaLNZHHqGNGVyeZXLtx6yYikcNK957e6+NsfXnMuWWCprnAVfYhNiKZhuyw3zPHzh8NOaz83Fpo2xc5/2n/jHa1/i+z1uGxNha1sXYAAHZ7OngNy5/4jLxcUWnf3XcEbbLSPF5G22rPHjkfULoYfGc9OVtrR+6m2nrPTksKfFIn5HsHx09V18Hi+nycrfln5/2176e9fm7fEZhdSJiY3hR0FIICCEBBF0GxAQTZA0QV2L4gyOKUl1v7b7bs7G2arzb+Xbb0lNesPn0VYHC49V473dFDpydMkAR31cf0QZdU1Bp6JUbJetrXC7pyY4Pq0rCQ233iC4+XBer0mCMWKI7tHJbis9TSUzXvDd2p5b1tK181gAAAsBkFiBCDDJBBkO4IJAcUHDjmDNrKaWnebdY3sO3slbnHI3gWuAPkkxExtI+b9GIB1ZmftPqy6SKoe9xe8SRuLXMBOjQRkOS83rrWrfy+lY6RHJvYoiY3dNV0iZC4xRATVbtGlwZHG0aulee6Bw1VGPRWy/nvyr7c59mU5IjlHV00fSGR7Wsp4/bZwLSysHVUYfvtI69x93aWF9FStuK88Fe0dbfZMZJmOXP+G1tFWz2dNWiNoObKVrQAd4Mr9px8g1YWy4MXKmPf52/pPDa3Wfs6WYBTAEuM0h1u+ond8Nuw9FXOuy9to9oj+k+XDow/DmRO2oXyxEcJpS082OcWnzBWdPE9TTpP7QicNJ7Lek6QyNq4aWWz2zQzPZJk14fEWXa4DI3a8m4Ats77r0Hhuutqa24+sejUzYop0elZI1wuCCF1FDJBCCEBByzY1TM1lHlc/og439JoPd23/dZ/NkGcWJzSdymdbi9waPhdELGIvDe0AHcG3ItzRKtxaV3Vvyy2XfoVXm/+dvaU16w8K05eC8c6Q1qIZWQc2KOLIJ3DVsMpHMNKtwRvkrHzRbpK46PxhlJSNboKaAD8gXr4c5fYN3nfd/dJFuoHyvp/wD1EqqWsfSUrY2iEM6172lxc9zQ+zRcANAcOJJvpZEPY9AseOI0bZ5GBkoe+KUNvsF7bHabfMAgg2ubZ5lEvSbIQZIIug+L4vT1T6rFaanAZGa0vMu2WljntY9zQACTfy1XM1c4ceWMl/To2MfFNdoU2G9EZusLTEywdbrJjePXvNiabu/EbLDLr8XBvEz7R/aYxTv0e3g6IxkAVM0tSAO4XmOAeAijsLeBuuNbxG+/+OsV+fWfvLYjFHfmu6GghgZ1cMbYmXJ2WgAXOp5+K0suW+W3Fed5WxERyhv2AqxnG0DcgoquRvyrhzQM2xV0jvBuw1oJ83Beh8CrP57duTU1U9IW8WIzRzNY1od17bjaJsHNycABuXoWovRLWf8Abj9XIbMm1s470P5XfsQg2sxNnvBzOY/cXCIbfbovpj1CJV1N0ejbqLlBZQYfGzRo9EHW0ID9yCsxt4EMvgxx+BWGSN6THyTXrD58M2jxXjXRbGBBkEGNTEHsew6PY5n5hZZ47cNosiY3jZs6H1fWUNPfvxM6iQbw+LsEH0B817Ck7xu589XpcKltIBucC3+FkheWWI8z0m6CUOISNmlD45QA1z43Bpe0aBwIINuOqC7wfC4KOFlPTs2Io72F7kkm5c47yTndB1koILkEgIPj9Bir3SVs4pKiVlTWzSRvijLmuiFmNzuNzVxNfSuTJ8cRt2mW1ima16OwYnOe7h9UebGN/wAzlo+Rj75K/dbxT6S6YMQxPRuH2b9rURtI8m7Srtg0nfJ9oZRa/wDq6OtxZ2kVJEPrSSyH0DQFXw6KP1Wn6RCf8npDGSpxWIbT4YKlo7zYXPjlt9UPuHHwuEimjycotNZ+e2yN8kdeaxw/FYZ4evY7ZjAd1m12XRlvebID3SN91r5dNkx5OCY59vn84WRaJjdXdAmNr6mtxDa7LCKKnbvbC0Nkc8jcXucD+Feu0Gn8jDFe/WXPzX4rbvRYpCxktG8bpHxnxvY/st1U9U3QIJsgxdGDqEGHsrPohBvQSglBjJu5oK3GYNuF7L222ll+G0Lfug+X9Hpnuga2T56EvgnH2sTix3rs3815TWYvKyzDfx24qrQLVZpsgyQVVHMKKrcHdmlrnA33R1mmfAPAGfEL0Phuo46cE9Yamam07w9kBZdRQu6OtDwAcnjXx8QoHQCoElADUGQCDzPTjFHNjbRQH/m64OjZbWKDSWY8AGkgcSQqdRmrhxzezOlZtO0NVHTMhjjiYLMiY1jB9VosF4jJecl5tPWXTiNo2bbrAYlyDG6BdQPL19LGzEBE9u1T4pA/rmZhpngs4ONuLbA8d662LJa2l44n82OeU/KVMxHHt2l34c802LM92DEojE7gKuAXjPhdm038IXS8F1E3xzjtPOP4lRqKbTEvR9IY7Cn/AMSP8pXbaz0kXdHJBmgICDJBKAgwm3c/2QV9aeyeYQfNsXp/Z8TlGkdfEKln+IitHMPNvVu9Vx/FsW9YvHbk2NPbns6muXCbTYEEgINVVTMlY6ORocx4s4Hgs6ZLUtxVRMRMbS5KHFpaG0VVtTUgyiqAC58bdzZwMyB9Mea9HpNdTLG08pamTFNXqKWojlaJI3h7D3XNIIPIhb6lZQ4g9uR7Q8dfVB1MxRm9pHKxUbDZ8pR+Pog89inTaMONPRxmqrNNkfNR396aQZNA4aqjNnx4a8V5ZVpNujjwjDXRuknnk6+snsZ5bWFh3Y4x7sbdw8yvJ67XW1NvSI6Q6GPFFIWJK0VjFBCCbKEsXyNb3jb9fRZRWZ6Il590ntOIwbI7FDDK+Q/aTAMY0+OyHmy6PD5Oktv1vMbe0dVW/FeNuzq6XUz3Uj5Ivn6VzKuA/aRHa+I2h5rDw3N5Woj0nl905q8VF5X1zKilpKhh7E0sUreTmXt5L2bmvUQHsjkEGxAQSgkIJQSg1T+7z/ZBwVhOyeaDxn9RKU+zMqmi76CZs+Wpg7kzeWw4u/AFTnxRkxzX1ZUna26vY4EAg3BAIO4g6FeRmNp2l0HQFAlB20VOxzSSLm9tVTkvMTyZRDa+gZuuPisYzWhPCppOibGuMlNK+lkOZMR2WuP1o82n0XRweLZcfKefuqtgrKWQYyzIT004+0jexx/9eS6FfG8f6qypnSz2ltHywciaOPxHXvPobLKfG8PaJR+GsxfgM82VXWySMOscIEEZHAlt3OHmtPN43knljrt7rK6aI6rfD6CGnYI4Y2xMG5otc8SdSfErj5c18s8V53bFaxEcnTdVpYkoOOauAJAF7b9ytri3jeUcTlfihGrmN8/5KtjT79pY8bgrOkUDPnKpjfAPbf0GZWxTR5J+GksZyRHWVd8qT1GVJEWtOs8oLWAcWMObz6BbEYMeLnln6R/1hxTb4Xo+jmHtgh2QS5znufK93ekkOrnfpbdZc/V5py5N55RHSPRbSvDC1c248DkeS1Ynad4ZvM9HpOqppcPce1QYhaLxppQ6SI/Fw8l7rSZozYa39f8A0uZkrw22fTaM9hvJbDBuQEEoMkBACDVUnu+f6IKzEZ2sjc9x2WNBc4nQNAuSfIIPnLDUYtG6WeV8FDLfqaeMhhkg3Onk1O0M9kEAAjVcLX+K2xXnHijnHWW1iwRMb2bI+iNGABBLLA4d1zJ3m34HEtI8CFy//wBDNM/nrEx7L/Kr2bKKOZgcydzHuY4hr2ZbbNzi33XbiBcZKcs47TxU5b9vSSu/d0qpLtww94ciqc0dJZVd1lQySgi6CLoAKCUBBNkFfV0hBLm5gm5G8LYpk5bSxmHn34BRlznup2Oe9znOJBN3E5nNb0azNFYiLTsr4K+jqp8Ogj7kMbLcGNB9bKu2fLbraZTFax2djGlxsBcqqZ25ylcQR7LQ3hrzWpe287rI6NjjYLEedrqMe1R1LTYOjdDKPpFrmujd5XePML0PgeadrYp94ampr0l9HoT2G8gvQtRvQSgIMY5QefDeg2IJCDVMM+QQeW6fRvkw6vYwZ+x1J8T/AG3ZBB4ltS9lHAIBtl0dOyMZlo2g0Bzre6NTyXlPLrbPbj5dZl0N54Y2ceD088gmMtXJ1jJ5IhsBjWtDDkSwtIz15Ec1fqL46bRWkbTG/P8AthWJnfeV/HewBNyALm1rnebblz5mJnktZqB0YfIA+3EEfv8Asq8sflZQtNpazIUCNkqROygkNQTZBFkEEoMUGL4mu1aD5KYtMGzD2aP6P6rLzLG0N8bGtGQA5LCZmeom6DCYXBQVlTb+0OEtvULs+CT/AJ5j5NfU/C97SCzByXqWi3oAQZWQapYQ7nxQaCyVvdd65oMDUSjU/wDz/og0T1zs8uWuaDkkqAbscCdoEOFjbZNwQUHzOOCXD5fYpr9VtH2GU918RzERdukaMrbwLhcPxHRzv5tPq2sOTtLvipiHukawB7wA86bVtL8T4rkze01is9IX7d3S1kiwS2Nj4oOinIa5p4EX5KLRvGyYasb6QNgAIBJcdmJjQC97vC+g8dyz02jnLO33+Ra/aHnn4viUmbqhtONzI42OIHi94NzyXVrotNT9O/usrp8k87TszhxnEY8xUNqAPdlja244B8YBHmCovodNePh29pTOnvHS2/u9VgWNsq2OcGmOSM7M0Z1Y7dnvadx3rjarS209tp5xPSWFbb8p6rPaWqliXoILkEIJQTZBLWIIk4IJtwsg0zE7iL3+CDTFhBmcLybFnbWQv+4XpfBtNem+S8bb9GlqbxPKHsadzWtAuTYLutZt69vj6IOOtxdsYOyNp+4a+qCp+Wqv6I9EHp0EIFkGqohDxbQ7igrn0Mg17Q32Ofof5Qc1bh0M8boaiJs0byNpj23vwNjvHEIPCdKMFNFNRMpKmWOOpkmjLJCJmsLIy9uztjatkRm47lz9Zgw1pOSaRP7Lcdrb7bppKeoa8OkqesbskbAjYwEnfcXK4WTJimu1abT7tuInfnLvDlrslHW9IoxNFFE5pb1gbPKbmJg+htDLaOmthdb+PRTwTe0duUd/dXbJz2hWiXr6momJuI3mni4Bre8RzOd1v4qeXirX6y2dLWLTN/o6LA3z01WTcQY1CXV0WjPyhJs932P+7z6wdX599aXie34eN/Xk0su3m8vR7XqyuAhIjKDMRoJ2UECyAXhBgZVAwJzucuf8K3HivknakTPsibRHVtjY93dY53wC6uHwXLfnkmK/vKi2prHRtGEzv1sweGq7Gn8L0+Gd9t59Za981rfJaYdgzI8zmd910VKwNNGfcHogxNHH9EIAo2cEGXs7eCDcgICAgIIcwHIgFBU410cgqupL9oOgkMkRDsg4tLDlvFnHJV5cUZKTSe6aztO6jq+jM7c2EPA4ZH0P8riZfCckfBMTDarqInrCqmpJ2d6M+hWlfR56daz/ACsjJWe7jMLNgx9U3q3AgssNkg63aqpveLbzM7/uy2jZ5OWmdRPka2F7qZ7tuMsBe5hIF2uGtssiuxi1Fc1Y3mIsyw5PK3iY5NeE4gyQSWuHCWTaBFnC5uLg6ZW9FfkjbZs6fJF4nb1d3XhVthc9AZYy2qlu0yyVDoyLjabHF2WAjUauPmuX4txcVa7coj+XOi3Fa0/N6x02i46w65QIMvP0QQXn/ZAWVYm07RG6EAk2tnyBJW1j0Gov0pP8MJy0ju6YcPmdow8ybD0XQxeB5Z55LRHtzU21Ne0O+nwI++63g3L4rp4fCNNj6xxe/wDSm2ovKwgwuFmjbnicyulWlaRtWNoUzMz1dbWAaCyyQmyAgICAgICAgICAglAQEEEINEtFE/vRtPkFE1i3WE7y5H4DTH/pgcslTbS4bdax9kxe0d3DP0MoHv6x0X9y2ztAkO2eBI1Cyrhx1jhiOSYyXid4lh/wVQ/QP5nfynk09Fv4vL6uSo/pvhj3bbobuG/af8bHPzWUY6xGyq2S153lvp+hFLH3DI3/AM01vTbWM6fFPWsfaEcdvVZRYDE0W2nnm9x/Uqv8Hp/9I+yfMt6tzcHgGrb8yVlGlwR0pH2hHHb1bm4fCNIx6K2KxXpCJmZb2xNGgA8lkhmgICAgIIQEBAQEEIJQEBAQEBBKAgICAgICAgICAgICAgICAgIIQEBAQYoJQSgICAgIJQEBAQEBAQEBAQEBAQEBAQEBAQQgICDFBKAgIJQEBBKAgICAgICAgICAgICAgICAgICAgICDBAQSgICCUBAQSgICAgICAgICAgICAgICAgICAgICDWEEoJQEBBKAgIJQEBAQEBAQEBAQEBAQEBAQEBAQEBBrQAglBKAglAQEBAQEEoCAgICAgICAgICAgICAgICAg1BBKCUBBKAglAQEBAQEEoCAgICAgICAgICAgICAgICD/9k=)"
      ]
    }
  ]
}